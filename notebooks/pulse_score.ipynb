{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6257c3b",
   "metadata": {},
   "source": [
    "# notebooks/pulse\\_score.ipynb\n",
    "\n",
    "**Overview**\n",
    "This notebook ingests Buffalo raw data from Athena, spatially joins to 2020 Census tracts, computes tract-level metrics (crime, vacancy, permits, licences, 311), derives a composite score, and stores results for visualization and LLM narration.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c548c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as geom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb23c02",
   "metadata": {},
   "source": [
    "\n",
    "Configure AWS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "wr.config.athena_workgroup = 'primary'\n",
    "DATABASE = 'civic_pulse'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20cfe5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2. Load Raw Tables from Athena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: read partition for a specific date\n",
    "def read_last_n_days(table, n=7):\n",
    "    query = f\"\"\"\n",
    "      SELECT *\n",
    "      FROM {DATABASE}.{table}\n",
    "      WHERE pulled_utc >= date_add('day', -{n}, current_timestamp)\n",
    "    \"\"\"\n",
    "    return wr.athena.read_sql_query(query, database=DATABASE)\n",
    "\n",
    "# example: 7-day window ending today\n",
    "yesterday = pd.Timestamp.utcnow().normalize() - pd.Timedelta(days=1)\n",
    "y, m, d = yesterday.year, f\"{yesterday.month:02}\", f\"{yesterday.day:02}\"\n",
    "\n",
    "crime_df = read_table('raw_buf_crime', y, m, d)\n",
    "viol_df  = read_table('raw_buf_viol',  y, m, d)\n",
    "perm_df  = read_table('raw_buf_permits',y, m, d)\n",
    "biz_df   = read_table('raw_buf_biz',    y, m, d)\n",
    "calls_df = read_table('raw_buf_311',    y, m, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b3ba9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3. Load 2020 Tract Shapefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NY State tracts (state FIPS 36) from TIGER 2024\n",
    "url = (\"https://www2.census.gov/geo/tiger/TIGER2024/TRACT/\"\n",
    "       \"tl_2024_36_tract.zip\")\n",
    "\n",
    "tracts = gpd.read_file(url)[[\"GEOID\", \"geometry\"]].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b13e08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Spatial Join Points → Tracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_points(df, lon='longitude', lat='latitude'):\n",
    "    gdf = gpd.GeoDataFrame(df,\n",
    "        geometry=gpd.points_from_xy(df[lon], df[lat]),\n",
    "        crs='EPSG:4326')\n",
    "    return gpd.sjoin(gdf, tracts, how='left', predicate='within')\n",
    "\n",
    "crime_gdf = join_points(crime_df)\n",
    "viol_gdf  = join_points(viol_df)\n",
    "perm_gdf  = join_points(perm_df, lon=None, lat=None)  # if no coords\n",
    "biz_gdf   = join_points(biz_df)\n",
    "calls_gdf = join_points(calls_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19191ae",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 5. Compute Tract-Level Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e12f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize metrics DataFrame with all tracts\n",
    "\n",
    "metrics = pd.DataFrame({'tract': tracts['GEOID20']})\n",
    "\n",
    "# 5.1 Crime per 1k\n",
    "crime_counts = crime_gdf.groupby('GEOID20').size().rename('crime_count')\n",
    "metrics = metrics.merge(crime_counts, left_on='tract', right_index=True, how='left').fillna(0)\n",
    "# TODO: load tract population from ACS baseline\n",
    "metrics['crime_per_1k'] = metrics['crime_count'] / (metrics['population']/1000)\n",
    "\n",
    "# 5.2 Vacant cases\n",
    "vac_counts = viol_gdf.groupby('GEOID20').size().rename('open_vacant_cases')\n",
    "metrics = metrics.merge(vac_counts, left_on='tract', right_index=True, how='left').fillna(0)\n",
    "\n",
    "# 5.3 Permits count\n",
    "perm_counts = perm_gdf.groupby('GEOID20').size().rename('permit_count')\n",
    "metrics = metrics.merge(perm_counts, left_on='tract', right_index=True, how='left').fillna(0)\n",
    "\n",
    "# 5.4 New licences\n",
    "dict_counts = biz_gdf.groupby('GEOID20').size().rename('new_licences')\n",
    "metrics = metrics.merge(dict_counts, left_on='tract', right_index=True, how='left').fillna(0)\n",
    "\n",
    "# 5.5 311 volume\n",
    "call_counts = calls_gdf.groupby('GEOID20').size().rename('311_volume')\n",
    "metrics = metrics.merge(call_counts, left_on='tract', right_index=True, how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372d533",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Composite Score & SHAP Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "def compute_score(df, features):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df[features])\n",
    "    df['score'] = X.sum(axis=1)\n",
    "    return df\n",
    "\n",
    "features = ['crime_per_1k','open_vacant_cases','permit_count','new_licences','311_volume']\n",
    "metrics = compute_score(metrics, features)\n",
    "\n",
    "# optional: train XGBoost to predict next-week 311 and compute SHAP values\n",
    "model = xgb.XGBRegressor()\n",
    "# TODO: build training set\n",
    "# fit, compute shap values, store per tract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47204c29",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 7. Save Results to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c43621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import boto3\n",
    "\n",
    "metrics['run_date'] = pd.Timestamp.utcnow()\n",
    "\n",
    "# write Parquet locally or to S3\n",
    "table = pa.Table.from_pandas(metrics)\n",
    "buf = pa.BufferOutputStream()\n",
    "pq.write_table(table, buf, compression='zstd')\n",
    "key = f\"analytics/buf_pulse_score/{y}/{m}/{d}/pulse_score.parquet\"\n",
    "\n",
    "boto3.client('s3').put_object(\n",
    "    Bucket=os.getenv('BUCKET'),\n",
    "    Key=key,\n",
    "    Body=buf.getvalue().to_pybytes()\n",
    ")\n",
    "print(\"Wrote composite metrics → s3://{}/{}\".format(os.getenv('BUCKET'),key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff1721",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "*Next:* Fill in ACS population load, training data for SHAP, and refine model fitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
