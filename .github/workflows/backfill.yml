name: backfill
on:
  workflow_dispatch:
    inputs:
      start_date:
        description: "Start date (YYYY-MM-DD) of lookback window"
        required: true
        type: string
      end_date:
        description: "End date (YYYY-MM-DD) of lookback window (optional, defaults to today)"
        required: false
        type: string
      dataset:
        description: "Comma-separated list of datasets to backfill (choose from 311, biz, viol, permits, crime)"
        required: true
        type: string

jobs:
  backfill:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ secrets.AWS_REGION }}
      BUCKET:                ${{ secrets.BUCKET }}
      SOCRATA_APP_TOKEN:     ${{ secrets.SOCRATA_APP_TOKEN }}
      ATHENA_WORKGROUP_NAME: ${{ secrets.ATHENA_WORKGROUP_NAME }}
      START_DATE: ${{ inputs.start_date }}
      END_DATE: ${{ inputs.end_date }}
      DATASET: ${{ inputs.dataset }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with: {python-version: '3.11'}

      - run: pip install -r requirements.txt

      - name: Run backfill
        run: |
          set -euo pipefail
          if [ -z "${END_DATE:-}" ]; then
            END_DATE=$(date +%F)
          fi
          if ! date -d "$START_DATE" >/dev/null 2>&1; then
            echo "Invalid START_DATE: $START_DATE" >&2
            exit 1
          fi
          if ! date -d "$END_DATE" >/dev/null 2>&1; then
            echo "Invalid END_DATE: $END_DATE" >&2
            exit 1
          fi
          start_ts=$(date -d "$START_DATE" +%s)
          end_ts=$(date -d "$END_DATE" +%s)
          if [ "$start_ts" -gt "$end_ts" ]; then
            echo "START_DATE ($START_DATE) is after END_DATE ($END_DATE)" >&2
            exit 1
          fi
          echo "Backfilling datasets: $DATASET from $START_DATE to $END_DATE"
          IFS=',' read -ra DS_ARRAY <<< "$DATASET"
          current_ts=$start_ts
          while [ "$current_ts" -le "$end_ts" ]; do
            TARGET_DATE=$(date -d "@$current_ts" +%F)
            echo ">>> Processing date: $TARGET_DATE"
            for ds in "${DS_ARRAY[@]}"; do
              ds_trim=$(echo "$ds" | xargs)
              echo "Running fetch_buf for $ds_trim"
              python data_ingest/fetch_buf_${ds_trim}.py
            done
            current_ts=$((current_ts + 86400))
            sleep 2
          done

      - name: Repair partitions
        run: |
          IFS=',' read -ra DS_ARRAY <<< "$DATASET"
          for ds in "${DS_ARRAY[@]}"; do
            ds_trim=$(echo "$ds" | xargs)
            tbl="raw_buf_${ds_trim}"
            echo "Repairing partition for $tbl"
            aws athena start-query-execution \
              --work-group "$ATHENA_WORKGROUP_NAME" \
              --query-string "MSCK REPAIR TABLE civic_pulse.${tbl};"
          done
